{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to /opt/anaconda3/envs/first/lib/python3.10/site-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(\n",
    "    model_complexity = 2,\n",
    "    min_detection_confidence=0.3,\n",
    "    min_tracking_confidence=0.3\n",
    ") as holistic:\n",
    "    for i in range(20) :\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        vis_image = image.copy()\n",
    "        mp_drawing.draw_landmarks(\n",
    "            vis_image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style()\n",
    "        )\n",
    "        mp_drawing.draw_landmarks(\n",
    "            vis_image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style()\n",
    "        )\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.left_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_connection = [\n",
    "    [0, 1], [1, 2], [2, 3], [3, 7],\n",
    "    [0, 4], [4, 5], [5, 6], [6, 8],\n",
    "    [9, 10],\n",
    "\n",
    "    [11, 13], [12, 14],\n",
    "    [13, 15], [14, 16]\n",
    "    [15, 17], [16, 18]\n",
    "    [15, 19], [16, 20]\n",
    "    [15, 21], [16, 22]\n",
    "    [17, 19], [18, 20],\n",
    "\n",
    "    [11, 23], [12, 24],\n",
    "    [23, 25], [24, 26],\n",
    "    [25, 27], [26, 28],\n",
    "    [27, 29], [28, 30],\n",
    "    [27, 31], [28, 32],\n",
    "    [29, 31], [30, 32],\n",
    "\n",
    "    [11, 12],\n",
    "    [23, 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (5, 6), (6, 7), (7, 8),\n",
    "    (9, 10), (10, 11), (11, 12),\n",
    "    (13, 14), (14, 15), (15, 16),\n",
    "    (17, 18), (18, 19), (19, 20),\n",
    "    (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)\n",
    "]\n",
    "\n",
    "POSE_CONNECTIONS = [\n",
    "    (0,1), (1,2), (2,3), (3,7),\n",
    "    (0,4), (4,5), (5,6), (6,8),\n",
    "    (9,10),\n",
    "    (11,13), (13,15), (15,17), (17,19), (19,15), (15,21),\n",
    "    (12,14), (14,16), (16,18), (18,20), (20,16), (16,22),\n",
    "    (11,12), (12,24), (24,23), (23,11)\n",
    "]\n",
    "\n",
    "FACE_CONNECTIONS = [\n",
    "    # Lips.\n",
    "    (61, 146), (146, 91), (91, 181), (181, 84), (84, 17),\n",
    "    (17, 314), (314, 405), (405, 321), (321, 375), (375, 291),\n",
    "    (61, 185), (185, 40), (40, 39), (39, 37), (37, 0),\n",
    "    (0, 267), (267, 269), (269, 270), (270, 409), (409, 291),\n",
    "    (78, 95), (95, 88), (88, 178), (178, 87), (87, 14),\n",
    "    (14, 317), (317, 402), (402, 318), (318, 324), (324, 308),\n",
    "    (78, 191), (191, 80), (80, 81), (81, 82), (82, 13),\n",
    "    (13, 312), (312, 311), (311, 310), (310, 415), (415, 308),\n",
    "    # Left eye.\n",
    "    (263, 249), (249, 390), (390, 373), (373, 374), (374, 380),\n",
    "    (380, 381), (381, 382), (382, 362), (263, 466), (466, 388),\n",
    "    (388, 387), (387, 386), (386, 385), (385, 384), (384, 398),\n",
    "    (398, 362),\n",
    "    # Left eyebrow.\n",
    "    (276, 283), (283, 282), (282, 295), (295, 285), (300, 293),\n",
    "    (293, 334), (334, 296), (296, 336),\n",
    "    # Right eye.\n",
    "    (33, 7), (7, 163), (163, 144), (144, 145), (145, 153),\n",
    "    (153, 154), (154, 155), (155, 133), (33, 246), (246, 161),\n",
    "    (161, 160), (160, 159), (159, 158), (158, 157), (157, 173),\n",
    "    (173, 133),\n",
    "    # Right eyebrow.\n",
    "    (46, 53), (53, 52), (52, 65), (65, 55), (70, 63), (63, 105),\n",
    "    (105, 66), (66, 107),\n",
    "    # Face oval.\n",
    "    (10, 338), (338, 297), (297, 332), (332, 284), (284, 251),\n",
    "    (251, 389), (389, 356), (356, 454), (454, 323), (323, 361),\n",
    "    (361, 288), (288, 397), (397, 365), (365, 379), (379, 378),\n",
    "    (378, 400), (400, 377), (377, 152), (152, 148), (148, 176),\n",
    "    (176, 149), (149, 150), (150, 136), (136, 172), (172, 58),\n",
    "    (58, 132), (132, 93), (93, 234), (234, 127), (127, 162),\n",
    "    (162, 21), (21, 54), (54, 103), (103, 67), (67, 109),\n",
    "    (109, 10)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.LANDMARK_FIELD_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NormalizedLandmarkList' object has no attribute 'landmars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results\u001b[39m.\u001b[39;49mleft_hand_landmarks\u001b[39m.\u001b[39;49mlandmars\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NormalizedLandmarkList' object has no attribute 'landmars'"
     ]
    }
   ],
   "source": [
    "results.left_hand_landmarks.landmars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
